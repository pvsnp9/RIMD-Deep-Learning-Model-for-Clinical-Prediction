Run Description: LOS task
Directory: mimic/los/0805-15-21-02
Model Arch: 
 MIMICLosDecayModel(
  (rim_decay_cell): RIMDCell(
    (gamma_x_l): CustomLinear(in_features=104, out_features=104, bias=True)
    (gamma_h_l): CustomLinear(in_features=104, out_features=104, bias=True)
    (input_key_layer): CustomLinear(in_features=104, out_features=64, bias=False)
    (input_value_layer): CustomLinear(in_features=104, out_features=32, bias=False)
    (input_dropout): Dropout(p=0.2694669454300502, inplace=False)
    (rnn): GroupGRUCell(
      (input_hidden): GroupLinear(in_features=136, out_features=312, num_blocks=2, bias=True)
      (hidden_hidden): GroupLinear(in_features=104, out_features=312, num_blocks=2, bias=True)
    )
    (input_query_layer): GroupLinear(in_features=104, out_features=64, num_blocks=2, bias=False)
    (comm_key_layer): GroupLinear(in_features=104, out_features=32, num_blocks=2, bias=False)
    (comm_value_layer): GroupLinear(in_features=104, out_features=104, num_blocks=2, bias=False)
    (comm_query_layer): GroupLinear(in_features=104, out_features=32, num_blocks=2, bias=False)
    (comm_attention_output): GroupLinear(in_features=104, out_features=104, num_blocks=2, bias=False)
    (comm_dropout): Dropout(p=0.12824679075614986, inplace=False)
  )
  (linear): Linear(in_features=224, out_features=1, bias=True)
)
Training, Validating, and Testing: RIMDecay model with GRU cell 
###################### Training ################
EPOCH [1], training loss: 3.830461866879543, val loss: 3.309937566860339, test_loss: 3.1940546527536915
###################### Training ################
EPOCH [2], training loss: 3.2259840921414735, val loss: 3.241433788771782, test_loss: 3.1172427061004364
###################### Training ################
EPOCH [3], training loss: 3.1846436190365948, val loss: 3.220455909457717, test_loss: 3.108046983834155
###################### Training ################
EPOCH [4], training loss: 3.1873251550572372, val loss: 3.1844201759640955, test_loss: 3.0816245073607336
###################### Training ################
EPOCH [5], training loss: 3.148608125970515, val loss: 3.171672519302575, test_loss: 3.0739041628704773
###################### Training ################
EPOCH [6], training loss: 3.1395003664054997, val loss: 3.1633216878599932, test_loss: 3.0648457139711507
###################### Training ################
EPOCH [7], training loss: 3.1372882825475075, val loss: 3.176631665124333, test_loss: 3.0697673197896576
###################### Training ################
EPOCH [8], training loss: 3.1143245720943082, val loss: 3.158387070157017, test_loss: 3.0502519250619056
###################### Training ################
EPOCH [9], training loss: 3.09468363479627, val loss: 3.1726316345062964, test_loss: 3.041424096111366
###################### Training ################
EPOCH [10], training loss: 3.073396925543463, val loss: 3.137368807362703, test_loss: 3.021912423068329
###################### Training ################
EPOCH [11], training loss: 3.0539513312055915, val loss: 3.1312903415175732, test_loss: 3.003908200098426
###################### Training ################
EPOCH [12], training loss: 3.0406989070484074, val loss: 3.1546702941594194, test_loss: 3.002488466251893
###################### Training ################
EPOCH [13], training loss: 3.0305659854691163, val loss: 3.1231829726647047, test_loss: 2.9889702750079734
###################### Training ################
EPOCH [14], training loss: 3.0124384471804, val loss: 3.124815161332772, test_loss: 3.005094879669856
###################### Training ################
EPOCH [15], training loss: 3.0109765178782486, val loss: 3.1228229247061803, test_loss: 2.992434379445486
###################### Training ################
EPOCH [16], training loss: 2.996139325027083, val loss: 3.1153403069695176, test_loss: 2.975213006662303
###################### Training ################
EPOCH [17], training loss: 2.9722631216846582, val loss: 3.146846430588729, test_loss: 3.010867203215795
###################### Training ################
EPOCH [18], training loss: 2.970612734855218, val loss: 3.170650115885635, test_loss: 3.00700924579891
###################### Training ################
EPOCH [19], training loss: 2.95690328341264, val loss: 3.1115047434618175, test_loss: 2.9618293159865274
###################### Training ################
EPOCH [20], training loss: 2.942449483584401, val loss: 3.192873343170391, test_loss: 3.019901740870619
###################### Training ################
EPOCH [21], training loss: 2.9403331200015983, val loss: 3.107195179996884, test_loss: 2.952225162368299
###################### Training ################
EPOCH [22], training loss: 2.9305721732685, val loss: 3.135174343173298, test_loss: 2.9630580948313634
###################### Training ################
EPOCH [23], training loss: 2.9174460671019795, val loss: 3.1057131264030464, test_loss: 2.9598562107465742
###################### Training ################
EPOCH [24], training loss: 2.9056090909900476, val loss: 3.1270486338943453, test_loss: 2.9986139765186732
###################### Training ################
EPOCH [25], training loss: 2.895048184139673, val loss: 3.1867797390466897, test_loss: 3.0418947178756057
###################### Training ################
EPOCH [26], training loss: 2.887141234499954, val loss: 3.288404550259873, test_loss: 3.1978956328888404
###################### Training ################
EPOCH [27], training loss: 2.8859547129442857, val loss: 3.2127242449337, test_loss: 3.0424558788203315
###################### Training ################
EPOCH [28], training loss: 2.861243391515419, val loss: 3.147243258982883, test_loss: 2.9792428720644653
###################### Training ################
EPOCH [29], training loss: 2.8549775275897025, val loss: 3.2177029522225133, test_loss: 3.0414675106700946
###################### Training ################
EPOCH [30], training loss: 2.8359102991512386, val loss: 3.1483264318923814, test_loss: 2.9704148000088755
###################### Training ################
EPOCH [31], training loss: 2.825796136090588, val loss: 3.1236306368992137, test_loss: 2.967807827082936
###################### Training ################
EPOCH [32], training loss: 2.8067073184112243, val loss: 3.2337359542057382, test_loss: 3.0556664690034916
###################### Training ################
EPOCH [33], training loss: 2.7844446634369153, val loss: 3.159158557869995, test_loss: 3.0117753731711474
###################### Training ################
EPOCH [34], training loss: 2.7824395316899024, val loss: 3.181530441588153, test_loss: 3.025841711125693
###################### Training ################
EPOCH [35], training loss: 2.7664984046017445, val loss: 3.1785084457352637, test_loss: 3.0250989358802074
###################### Training ################
EPOCH [36], training loss: 2.750932717801735, val loss: 3.2029960424453607, test_loss: 3.045081934658378
###################### Training ################
EPOCH [37], training loss: 2.726645583293111, val loss: 3.1877695428219006, test_loss: 3.015661923936583
###################### Training ################
EPOCH [38], training loss: 2.717613874869203, val loss: 3.2382975237345413, test_loss: 3.104895470043649
###################### Training ################
EPOCH [39], training loss: 2.704536119432354, val loss: 3.1955365564845617, test_loss: 3.0617460772081277
###################### Training ################
EPOCH [40], training loss: 2.700620506519458, val loss: 3.2959933715010408, test_loss: 3.192763033207524
###################### Training ################
EPOCH [41], training loss: 2.7299946117959295, val loss: 3.288980727523381, test_loss: 3.1289840469376227
###################### Training ################
EPOCH [42], training loss: 2.682145501857617, val loss: 3.1853568297861328, test_loss: 3.0327622748478382
###################### Training ################
EPOCH [43], training loss: 2.6550538890736557, val loss: 3.22088855730131, test_loss: 3.0459780765516475
###################### Training ################
EPOCH [44], training loss: 2.6153429112705497, val loss: 3.251561831102561, test_loss: 3.0989997708088595
###################### Training ################
EPOCH [45], training loss: 2.6004555616091727, val loss: 3.2838739451245136, test_loss: 3.0797691090624775
###################### Training ################
EPOCH [46], training loss: 2.5785249407873505, val loss: 3.2263819620211724, test_loss: 3.115268690783688
###################### Training ################
EPOCH [47], training loss: 2.56970653565831, val loss: 3.249956016307553, test_loss: 3.081506745526993
###################### Training ################
EPOCH [48], training loss: 2.531069711697939, val loss: 3.583268235558023, test_loss: 3.3798960151815103
###################### Training ################
EPOCH [49], training loss: 2.5368321500095634, val loss: 3.4468842423952797, test_loss: 3.3590601468241936
###################### Training ################
EPOCH [50], training loss: 2.4764352111912094, val loss: 3.366765887729964, test_loss: 3.2557476457112267
